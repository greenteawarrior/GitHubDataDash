[{"original_position": 13, "diff_hunk": "@@ -1,31 +1,167 @@\n+\"\"\"Blocks native serialization - tar files with pickles and numpy arrays.\n+\n+This module provides :func:`load` and :func:`dump` functions that can serve\n+as drop-in replacement for the respective functions from the standard\n+:mod:`pickle` module. The main differences between them and the standard\n+ones are:\n+\n+    - The dump is physically a tarball, in which the pickle is stored\n+      as '_pkl' file.\n+\n+    - Parts of the dumped object can be pickled separately but be\n+      referenced from '_pkl' file using the persisent id mechanism (see\n+      :mod:`pickle`) docs. Such parts are stored as arbitrarily named files", "url": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/42666453", "created_at": "2015-10-21T18:55:22Z", "body": "The closing parenthesis should be placed after the word _docs_.", "updated_at": "2015-10-28T19:39:42Z", "html_url": "https://github.com/mila-udem/blocks/pull/877#discussion_r42666453", "pull_request_url": "https://api.github.com/repos/mila-udem/blocks/pulls/877", "_links": {"self": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/42666453"}, "html": {"href": "https://github.com/mila-udem/blocks/pull/877#discussion_r42666453"}, "pull_request": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/877"}}, "commit_id": "0db09ae47e6804b03fa496cdf3a0c83191fbcdbe", "user": {"following_url": "https://api.github.com/users/rizar/following{/other_user}", "events_url": "https://api.github.com/users/rizar/events{/privacy}", "organizations_url": "https://api.github.com/users/rizar/orgs", "url": "https://api.github.com/users/rizar", "gists_url": "https://api.github.com/users/rizar/gists{/gist_id}", "html_url": "https://github.com/rizar", "subscriptions_url": "https://api.github.com/users/rizar/subscriptions", "avatar_url": "https://avatars.githubusercontent.com/u/654434?v=3", "repos_url": "https://api.github.com/users/rizar/repos", "received_events_url": "https://api.github.com/users/rizar/received_events", "gravatar_id": "", "starred_url": "https://api.github.com/users/rizar/starred{/owner}{/repo}", "site_admin": false, "login": "rizar", "type": "User", "id": 654434, "followers_url": "https://api.github.com/users/rizar/followers"}, "path": "blocks/serialization.py", "position": null, "original_commit_id": "566045a7b879685e70f53b73f974782256975290", "id": 42666453}, {"original_position": 28, "diff_hunk": "@@ -1,31 +1,167 @@\n+\"\"\"Blocks native serialization - tar files with pickles and numpy arrays.\n+\n+This module provides :func:`load` and :func:`dump` functions that can serve\n+as drop-in replacement for the respective functions from the standard\n+:mod:`pickle` module. The main differences between them and the standard\n+ones are:\n+\n+    - The dump is physically a tarball, in which the pickle is stored\n+      as '_pkl' file.\n+\n+    - Parts of the dumped object can be pickled separately but be\n+      referenced from '_pkl' file using the persisent id mechanism (see\n+      :mod:`pickle`) docs. Such parts are stored as arbitrarily named files\n+      in the tarball. The benefit is that when unpickling '_pkl' breaks for\n+      some reason (typically because of changes in the codebase used), one\n+      can still have access to certain parts of the dumped object.\n+\n+    - A special file '_parameters' in the tarball can contain the data\n+      of a selected set of Theano shared variables. Again, this data is\n+      referenced from `_pkl` using persistent id mechanism, which means\n+      that no duplication takes place. The goal here is to save the values\n+      of the parameters (this is what these shared variables are in most\n+      cases) in the most robust way possible. The actual format for\n+      '_parameters' file is the one used by :func:`numpy.savez`, i.e. a zip\n+      file of numpy arrays.\n+\n+    - Pickling of the whole object in fact can be bypassed if pickling of\n+      some parts and parameters is sufficient.", "url": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/42666565", "created_at": "2015-10-21T18:56:16Z", "body": "and -> and/or", "updated_at": "2015-10-28T19:39:42Z", "html_url": "https://github.com/mila-udem/blocks/pull/877#discussion_r42666565", "pull_request_url": "https://api.github.com/repos/mila-udem/blocks/pulls/877", "_links": {"self": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/42666565"}, "html": {"href": "https://github.com/mila-udem/blocks/pull/877#discussion_r42666565"}, "pull_request": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/877"}}, "commit_id": "0db09ae47e6804b03fa496cdf3a0c83191fbcdbe", "user": {"following_url": "https://api.github.com/users/rizar/following{/other_user}", "events_url": "https://api.github.com/users/rizar/events{/privacy}", "organizations_url": "https://api.github.com/users/rizar/orgs", "url": "https://api.github.com/users/rizar", "gists_url": "https://api.github.com/users/rizar/gists{/gist_id}", "html_url": "https://github.com/rizar", "subscriptions_url": "https://api.github.com/users/rizar/subscriptions", "avatar_url": "https://avatars.githubusercontent.com/u/654434?v=3", "repos_url": "https://api.github.com/users/rizar/repos", "received_events_url": "https://api.github.com/users/rizar/received_events", "gravatar_id": "", "starred_url": "https://api.github.com/users/rizar/starred{/owner}{/repo}", "site_admin": false, "login": "rizar", "type": "User", "id": 654434, "followers_url": "https://api.github.com/users/rizar/followers"}, "path": "blocks/serialization.py", "position": null, "original_commit_id": "566045a7b879685e70f53b73f974782256975290", "id": 42666565}, {"original_position": 91, "diff_hunk": "@@ -1,31 +1,167 @@\n+\"\"\"Blocks native serialization - tar files with pickles and numpy arrays.\n+\n+This module provides :func:`load` and :func:`dump` functions that can serve\n+as drop-in replacement for the respective functions from the standard\n+:mod:`pickle` module. The main differences between them and the standard\n+ones are:\n+\n+    - The dump is physically a tarball, in which the pickle is stored\n+      as '_pkl' file.\n+\n+    - Parts of the dumped object can be pickled separately but be\n+      referenced from '_pkl' file using the persisent id mechanism (see\n+      :mod:`pickle`) docs. Such parts are stored as arbitrarily named files\n+      in the tarball. The benefit is that when unpickling '_pkl' breaks for\n+      some reason (typically because of changes in the codebase used), one\n+      can still have access to certain parts of the dumped object.\n+\n+    - A special file '_parameters' in the tarball can contain the data\n+      of a selected set of Theano shared variables. Again, this data is\n+      referenced from `_pkl` using persistent id mechanism, which means\n+      that no duplication takes place. The goal here is to save the values\n+      of the parameters (this is what these shared variables are in most\n+      cases) in the most robust way possible. The actual format for\n+      '_parameters' file is the one used by :func:`numpy.savez`, i.e. a zip\n+      file of numpy arrays.\n+\n+    - Pickling of the whole object in fact can be bypassed if pickling of\n+      some parts and parameters is sufficient.\n+\n+    - The :func:`dump` strives to catch situations when the user tries\n+      to pickle a function or a class not defined in the global namespace\n+      and give a meaningful warning.\n+\n+If briefly, this module proposes a dumping mechanism which allows for\n+greater robustness and persistency than standard pickling.\n+\n+Examples\n+--------\n+\n+Consider a standard main loop (without an algorithm and a data stream\n+for brevity)\n+\n+>>> from theano import tensor\n+>>> from blocks.main_loop import MainLoop\n+>>> from blocks.bricks import MLP, Tanh, Softmax\n+>>> from blocks.model import Model\n+>>> mlp = MLP([Tanh(), None], [784, 10, 10])\n+>>> x = tensor.matrix('features')\n+>>> y = tensor.lmatrix('targets')\n+>>> cost = Softmax().categorical_cross_entropy(\n+...            y.flatten(), mlp.apply(tensor.flatten(x, outdim=2)))\n+>>> main_loop = MainLoop(None, None, model=Model(cost))\n+\n+Let's see how the main loop is dumped by :func:`dump`\n+\n+>>> from blocks.serialization import dump, load\n+>>> import tarfile\n+>>> with open('main_loop.tar', 'w') as dst:\n+...     dump(main_loop, dst)\n+>>> tarball = tarfile.open('main_loop.tar', 'r')\n+>>> tarball # doctest: +ELLIPSIS\n+<tarfile.TarFile object at ...>\n+>>> tarball.getnames()\n+['_pkl']\n+>>> tarball.close()\n+\n+As promised, the dump is a tarball. Since we did not ask for any additional\n+magic, it just contains the pickled main loop in '_pkl' file.\n+\n+Let's do something more interesting:\n+\n+>>> with open('main_loop.tar', 'w') as dst:\n+...     dump(main_loop, dst,\n+...          pickle_separately={'log': main_loop.log},\n+...          parameters=main_loop.model.parameters)\n+>>> tarball = tarfile.open('main_loop.tar', 'r')\n+>>> tarball.getnames()\n+['_parameters', 'log', '_pkl']\n+\n+As requested by specifying `pickle_separately` and `_parameters` arguments,\n+the log was pickled separately and the parameters were saved in a zip file.\n+\n+>>> import numpy\n+>>> ps = numpy.load(tarball.extractfile(tarball.getmember('_parameters')))\n+>>> sorted(ps.keys()) # doctest: +ELLIPSIS\n+['|mlp|linear_0.W', '|mlp|linear_0.b', '|mlp|linear_1.W', '|mlp|lin...]\n+>>> ps.close()\n+\n+The names for parameters are chosen intellegently to reflect their\n+position in the brick hierarchy, if they belong to bricks, and by\n+simpling using the `.name` attribute, if they do not.", "url": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/42666726", "created_at": "2015-10-21T18:57:33Z", "body": "simpling -> simply", "updated_at": "2015-10-28T19:39:42Z", "html_url": "https://github.com/mila-udem/blocks/pull/877#discussion_r42666726", "pull_request_url": "https://api.github.com/repos/mila-udem/blocks/pulls/877", "_links": {"self": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/42666726"}, "html": {"href": "https://github.com/mila-udem/blocks/pull/877#discussion_r42666726"}, "pull_request": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/877"}}, "commit_id": "0db09ae47e6804b03fa496cdf3a0c83191fbcdbe", "user": {"following_url": "https://api.github.com/users/rizar/following{/other_user}", "events_url": "https://api.github.com/users/rizar/events{/privacy}", "organizations_url": "https://api.github.com/users/rizar/orgs", "url": "https://api.github.com/users/rizar", "gists_url": "https://api.github.com/users/rizar/gists{/gist_id}", "html_url": "https://github.com/rizar", "subscriptions_url": "https://api.github.com/users/rizar/subscriptions", "avatar_url": "https://avatars.githubusercontent.com/u/654434?v=3", "repos_url": "https://api.github.com/users/rizar/repos", "received_events_url": "https://api.github.com/users/rizar/received_events", "gravatar_id": "", "starred_url": "https://api.github.com/users/rizar/starred{/owner}{/repo}", "site_admin": false, "login": "rizar", "type": "User", "id": 654434, "followers_url": "https://api.github.com/users/rizar/followers"}, "path": "blocks/serialization.py", "position": null, "original_commit_id": "566045a7b879685e70f53b73f974782256975290", "id": 42666726}, {"original_position": 367, "diff_hunk": "@@ -33,142 +169,93 @@\n resume your model outside of a namespace containing this function. In other \\\n words, you can only call `continue_training` from within this script.\"\"\"\n \n+LOAD_ERROR_MESSAGE = \"\"\"\n \n-class PersistentParameterID(PersistentSharedVariableID):\n-    \"\"\"Persist the names of parameter arrays in the zip file.\n-\n-    Only Theano shared variables are persisted to the zip file using this\n-    method. Names are determined using the brick hierarchy, or the shared\n-    variable name.\n-\n-    Parameters\n-    ----------\n-    allow_unnamed : bool, optional\n-        Allow shared variables without a name to be persisted. Defaults to\n-        ``True``.\n-    allow_duplicates : bool, optional\n-        Allow multiple shared variables to have the same name, in which\n-        case they will be numbered e.g. `x`, `x_2`, `x_3`, etc. Defaults to\n-        ``True``.\n-\n-    Raises\n-    ------\n-    ValueError\n-        If an unnamed shared variable is encountered and `allow_unnamed` is\n-        ``False``, or if two shared variables have the same name, and\n-        `allow_duplicates` is ``False``.\n-\n-    \"\"\"\n-    def __call__(self, obj):\n-        if isinstance(obj, SharedVariable):\n-            super(PersistentParameterID, self).__call__(obj)\n-            if hasattr(obj.tag, 'annotations'):\n-                name = '{}.{}'.format(\n-                    BRICK_DELIMITER.join([brick.name for brick in\n-                                          get_brick(obj).get_unique_path()]),\n-                    obj.name\n-                )\n-            else:\n-                name = obj.name\n-            self.ndarray_names[id(obj.container.storage[0])] = name\n-        if id(obj) in self.ndarray_names:\n-            PersistentCudaNdarrayID.__call__(self, obj)\n-\n-\n-class PicklerWithWarning(_Pickler):\n-    dispatch = _Pickler.dispatch.copy()\n-\n-    def save_global(self, obj, name=None, **kwargs):\n-        module = getattr(obj, '__module__', None)\n-        if module == '__main__':\n-            warnings.warn(\n-                MAIN_MODULE_WARNING.format(kwargs.get('name', obj.__name__))\n-            )\n-        _Pickler.save_global(self, obj, name=name, **kwargs)\n-\n-    dispatch[six.types.FunctionType] = save_global\n-    if six.PY2:\n-        dispatch[six.types.ClassType] = save_global\n-        dispatch[six.types.BuiltinFunctionType] = save_global\n-        dispatch[six.types.TypeType] = save_global\n+There is no object to load in this archive (ie you saved your object using \\\n+dump(pickle_whole=False)). To load the parts that have been pickled \\\n+separately, if any, use load_part(). If you want to load the parameters \\\n+that you saved separately, if any, use load_parameters().\"\"\"\n \n \n-def dump(obj, file_handler, protocol=DEFAULT_PROTOCOL,\n-         persistent_id=PersistentParameterID, use_cpickle=False):\n-    \"\"\"Pickles an object to a zip file using external persistence.\n+def dump(object_, file_,\n+         parameters=None, pickle_separately=None,\n+         pickle_whole=True, use_cpickle=False, **kwargs):\n+    r\"\"\"Pickles an object saving some of its parts separately.\n \n     Parameters\n     ----------\n-    obj : object\n-        The object to pickle.\n-    file_handler : file\n-        The file handle to save the object to.\n-    protocol : int, optional\n-        The pickling protocol to use. Unlike Python's built-in pickle, the\n-        default is set to `2` instead of 0 for Python 2. The Python 3\n-        default (level 3) is maintained.\n-    persistent_id : callable\n-        The callable that persists certain objects in the object hierarchy\n-        to separate files inside of the zip file. For example,\n-        :class:`PersistentNdarrayID` saves any :class:`numpy.ndarray` to a\n-        separate NPY file inside of the zip file.\n+    object_ : object\n+        The object to be pickled.\n+    file_ : file\n+        The destination for saving.\n+    parameters : list, optional\n+        Shared variables whose internal numpy arrays should be saved\n+        separately in the `_parameters` field of the zip file.\n+    pickle_separately : dict, optional\n+        Specifies the components of `object_` that should be pickled\n+        separately. The keys will be used as field names in the resulting\n+        tar file. The values are the actual parts to save separately.\n+        '_pkl` and `_parameters` are reserved keys and can't be used.\n+    pickle_whole : bool, optional\n+        When ``False``, the whole object is not pickled, only its\n+        components are. Default: True\n     use_cpickle : bool\n-        This enables the use of C-version of `pickle` (known as ``cPickle``\n-        in Python 2). Note that this disables warnings about trying to\n-        pickle objects in the ``__main__`` namespace.\n-\n-    Notes\n-    -----\n-    The final file is simply a zipped file containing at least one file,\n-    `pkl`, which contains the pickled object. It can contain any other\n-    number of external objects. Note that the zip files are compatible with\n-    NumPy's :func:`numpy.load` function.\n-\n-    >>> import numpy\n-    >>> from blocks.bricks import MLP, Identity\n-    >>> from blocks.initialization import Constant\n-    >>> mlp = MLP([Identity()], [10, 10], weights_init=Constant(0.),\n-    ...           biases_init=Constant(0.))\n-    >>> mlp.initialize()\n-    >>> with open('model.zip', 'wb') as f:\n-    ...     dump(mlp, f)\n-    >>> 'mlp-linear_0.W' in numpy.load('model.zip').keys()\n-    True\n-    >>> 'mlp-linear_0.b' in numpy.load('model.zip').keys()\n-    True\n-    >>> numpy.load('model.zip')['mlp-linear_0.W'].shape\n-    (10, 10)\n-    >>> with open('model.zip', 'rb') as f:\n-    ...     mlp2 = load(f)\n-    >>> mlp2  # doctest: +ELLIPSIS\n-    <blocks.bricks.MLP object at ...: name=mlp>\n+        Use cPickle instead of pickle. Setting it to true will disable the\n+        warning message if you try to pickle objects from the main module!\n+        Be sure that you don't have the warning before turning this flag\n+        on. Default: False.\n+    \\*\\*kwargs\n+        Keyword arguments to be passed to `pickle.Pickler`.\n \n     \"\"\"\n-    with closing(zipfile.ZipFile(file_handler, 'w', zipfile.ZIP_DEFLATED,\n-                                 allowZip64=True)) as zip_file:\n-        def func(f):\n-            if use_cpickle:\n-                p = cPickle.Pickler(f, protocol=protocol)\n-            else:\n-                p = PicklerWithWarning(f, protocol=protocol)\n-            p.persistent_id = persistent_id(zip_file)\n-            p.dump(obj)\n-        pkl_utils.zipadd(func, zip_file, 'pkl')\n-\n-\n-# A thin wrapper around Theano load.\n-load = pkl_utils.load\n-\n-\n-def secure_dump(object_, path, dump_function=dump, **kwargs):\n+    if not pickle_separately:\n+        pickle_separately = {}\n+    if '_pkl' in pickle_separately or '_parameters' in pickle_separately:\n+        raise ValueError(\"_pkl and _parameters are reserved names and can't\" \\\n+                         \" be used as keys in pickle_separately.\")\n+\n+    if use_cpickle:\n+        pickler = cPickle.Pickler\n+    else:\n+        pickler = _PicklerWithWarning\n+\n+    with closing(tarfile.TarFile(fileobj=file_, mode='w')) as tar_file:\n+        external_objects = {}\n+        def _save_parameters(f):\n+            renamer = _Renamer()\n+            named_parameters = {renamer(p): p for p in parameters}\n+            numpy.savez(f, **{name: p.get_value()\n+                              for name, p in named_parameters.items()})\n+\n+            for name, p in named_parameters.items():\n+                array_ = p.container.storage[0]\n+                external_objects[id(array_)] = _mangle_parameter_name(\n+                    type(array_), name)\n+        if parameters:\n+            _taradd(_save_parameters, tar_file, '_parameters')\n+        if pickle_separately:\n+            for name, component in six.iteritems(pickle_separately):\n+                def _pickle_separately(f):", "url": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/42675161", "created_at": "2015-10-21T20:08:44Z", "body": "As we discussed, the fact that we do not add ids of the objects to  `external_objects` here means they will be pickled together with the whole object. We should decide if we are fine with that, and if yes, change the docstring of the module.", "updated_at": "2015-10-28T19:39:42Z", "html_url": "https://github.com/mila-udem/blocks/pull/877#discussion_r42675161", "pull_request_url": "https://api.github.com/repos/mila-udem/blocks/pulls/877", "_links": {"self": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/42675161"}, "html": {"href": "https://github.com/mila-udem/blocks/pull/877#discussion_r42675161"}, "pull_request": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/877"}}, "commit_id": "0db09ae47e6804b03fa496cdf3a0c83191fbcdbe", "user": {"following_url": "https://api.github.com/users/rizar/following{/other_user}", "events_url": "https://api.github.com/users/rizar/events{/privacy}", "organizations_url": "https://api.github.com/users/rizar/orgs", "url": "https://api.github.com/users/rizar", "gists_url": "https://api.github.com/users/rizar/gists{/gist_id}", "html_url": "https://github.com/rizar", "subscriptions_url": "https://api.github.com/users/rizar/subscriptions", "avatar_url": "https://avatars.githubusercontent.com/u/654434?v=3", "repos_url": "https://api.github.com/users/rizar/repos", "received_events_url": "https://api.github.com/users/rizar/received_events", "gravatar_id": "", "starred_url": "https://api.github.com/users/rizar/starred{/owner}{/repo}", "site_admin": false, "login": "rizar", "type": "User", "id": 654434, "followers_url": "https://api.github.com/users/rizar/followers"}, "path": "blocks/serialization.py", "position": null, "original_commit_id": "566045a7b879685e70f53b73f974782256975290", "id": 42675161}, {"original_position": 331, "diff_hunk": "@@ -34,141 +142,65 @@\n words, you can only call `continue_training` from within this script.\"\"\"\n \n \n-class PersistentParameterID(PersistentSharedVariableID):\n-    \"\"\"Persist the names of parameter arrays in the zip file.\n-\n-    Only Theano shared variables are persisted to the zip file using this\n-    method. Names are determined using the brick hierarchy, or the shared\n-    variable name.\n+def dump(object_, file_, parameters=None, use_cpickle=False,\n+         protocol=DEFAULT_PROTOCOL, **kwargs):\n+    r\"\"\"Pickles an object saving optionnaly its parameters separately.\n \n     Parameters\n     ----------\n-    allow_unnamed : bool, optional\n-        Allow shared variables without a name to be persisted. Defaults to\n-        ``True``.\n-    allow_duplicates : bool, optional\n-        Allow multiple shared variables to have the same name, in which\n-        case they will be numbered e.g. `x`, `x_2`, `x_3`, etc. Defaults to\n-        ``True``.\n-\n-    Raises\n-    ------\n-    ValueError\n-        If an unnamed shared variable is encountered and `allow_unnamed` is\n-        ``False``, or if two shared variables have the same name, and\n-        `allow_duplicates` is ``False``.\n-\n-    \"\"\"\n-    def __call__(self, obj):\n-        if isinstance(obj, SharedVariable):\n-            super(PersistentParameterID, self).__call__(obj)\n-            if hasattr(obj.tag, 'annotations'):\n-                name = '{}.{}'.format(\n-                    BRICK_DELIMITER.join([brick.name for brick in\n-                                          get_brick(obj).get_unique_path()]),\n-                    obj.name\n-                )\n-            else:\n-                name = obj.name\n-            self.ndarray_names[id(obj.container.storage[0])] = name\n-        if id(obj) in self.ndarray_names:\n-            PersistentCudaNdarrayID.__call__(self, obj)\n-\n-\n-class PicklerWithWarning(_Pickler):\n-    dispatch = _Pickler.dispatch.copy()\n-\n-    def save_global(self, obj, name=None, **kwargs):\n-        module = getattr(obj, '__module__', None)\n-        if module == '__main__':\n-            warnings.warn(\n-                MAIN_MODULE_WARNING.format(kwargs.get('name', obj.__name__))\n-            )\n-        _Pickler.save_global(self, obj, name=name, **kwargs)\n-\n-    dispatch[six.types.FunctionType] = save_global\n-    if six.PY2:\n-        dispatch[six.types.ClassType] = save_global\n-        dispatch[six.types.BuiltinFunctionType] = save_global\n-        dispatch[six.types.TypeType] = save_global\n-\n-\n-def dump(obj, file_handler, protocol=DEFAULT_PROTOCOL,\n-         persistent_id=PersistentParameterID, use_cpickle=False):\n-    \"\"\"Pickles an object to a zip file using external persistence.\n-\n-    Parameters\n-    ----------\n-    obj : object\n+    object_ : object\n         The object to pickle.\n-    file_handler : file\n-        The file handle to save the object to.\n+    file_ : file\n+        The destination for saving.\n+    parameters : list, optional\n+        Shared variables whose internal numpy arrays should be saved\n+        separately in the `_parameters` field of the tar file.\n+    use_cpickle : bool\n+        Use cPickle instead of pickle. Setting it to true will disable the\n+        warning message if you try to pickle objects from the main module,\n+        so be sure that there is no warning before turning this flag\n+        on. Default: False.\n     protocol : int, optional\n         The pickling protocol to use. Unlike Python's built-in pickle, the\n         default is set to `2` instead of 0 for Python 2. The Python 3\n         default (level 3) is maintained.\n-    persistent_id : callable\n-        The callable that persists certain objects in the object hierarchy\n-        to separate files inside of the zip file. For example,\n-        :class:`PersistentNdarrayID` saves any :class:`numpy.ndarray` to a\n-        separate NPY file inside of the zip file.\n-    use_cpickle : bool\n-        This enables the use of C-version of `pickle` (known as ``cPickle``\n-        in Python 2). Note that this disables warnings about trying to\n-        pickle objects in the ``__main__`` namespace.\n-\n-    Notes\n-    -----\n-    The final file is simply a zipped file containing at least one file,\n-    `pkl`, which contains the pickled object. It can contain any other\n-    number of external objects. Note that the zip files are compatible with\n-    NumPy's :func:`numpy.load` function.\n-\n-    >>> import numpy\n-    >>> from blocks.bricks import MLP, Identity\n-    >>> from blocks.initialization import Constant\n-    >>> mlp = MLP([Identity()], [10, 10], weights_init=Constant(0.),\n-    ...           biases_init=Constant(0.))\n-    >>> mlp.initialize()\n-    >>> with open('model.zip', 'wb') as f:\n-    ...     dump(mlp, f)\n-    >>> 'mlp-linear_0.W' in numpy.load('model.zip').keys()\n-    True\n-    >>> 'mlp-linear_0.b' in numpy.load('model.zip').keys()\n-    True\n-    >>> numpy.load('model.zip')['mlp-linear_0.W'].shape\n-    (10, 10)\n-    >>> with open('model.zip', 'rb') as f:\n-    ...     mlp2 = load(f)\n-    >>> mlp2  # doctest: +ELLIPSIS\n-    <blocks.bricks.MLP object at ...: name=mlp>\n+    \\*\\*kwargs\n+        Keyword arguments to be passed to `pickle.Pickler`.\n \n     \"\"\"\n-    with closing(zipfile.ZipFile(file_handler, 'w', zipfile.ZIP_DEFLATED,\n-                                 allowZip64=True)) as zip_file:\n-        def func(f):\n-            if use_cpickle:\n-                p = cPickle.Pickler(f, protocol=protocol)\n-            else:\n-                p = PicklerWithWarning(f, protocol=protocol)\n-            p.persistent_id = persistent_id(zip_file)\n-            p.dump(obj)\n-        pkl_utils.zipadd(func, zip_file, 'pkl')\n-\n-\n-# A thin wrapper around Theano load.\n-load = pkl_utils.load\n-\n-\n-def secure_dump(object_, path, dump_function=dump, **kwargs):\n+    if use_cpickle:\n+        pickler = cPickle.Pickler\n+    else:\n+        pickler = _PicklerWithWarning\n+    with closing(tarfile.TarFile(fileobj=file_, mode='w')) as tar_file:\n+        external_objects = {}\n+        def _save_parameters(f):\n+            renamer = _Renamer()\n+            named_parameters = {renamer(p): p for p in parameters}\n+            numpy.savez(f, **{n: p.get_value()\n+                              for n, p in named_parameters.items()})\n+            for n, p in named_parameters.items():\n+                array_ = p.container.storage[0]\n+                external_objects[id(array_)] = _mangle_parameter_name(\n+                    type(array_), n)\n+        if parameters:\n+            _taradd(_save_parameters, tar_file, '_parameters')\n+        def _save_object(f):\n+            p = pickler(f, protocol=protocol, **kwargs)\n+            p.persistent_id = _PersistentID(external_objects)\n+            p.dump(object_)\n+        _taradd(_save_object, tar_file, '_pkl')\n+\n+\n+def secure_dump(object_, file_, dump_function=dump, **kwargs):\n     r\"\"\"Robust serialization - does not corrupt your files when failed.\n \n     Parameters\n     ----------\n     object_ : object\n         The object to be saved to the disk.\n-    path : str\n-        The destination path.\n+    file_ : str\n+        The destination for saving.", "url": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/45527629", "created_at": "2015-11-20T22:32:35Z", "body": "What is the reasoning behind this renaming?", "updated_at": "2015-11-20T22:32:35Z", "html_url": "https://github.com/mila-udem/blocks/pull/877#discussion_r45527629", "pull_request_url": "https://api.github.com/repos/mila-udem/blocks/pulls/877", "_links": {"self": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/45527629"}, "html": {"href": "https://github.com/mila-udem/blocks/pull/877#discussion_r45527629"}, "pull_request": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/877"}}, "commit_id": "0db09ae47e6804b03fa496cdf3a0c83191fbcdbe", "user": {"following_url": "https://api.github.com/users/rizar/following{/other_user}", "events_url": "https://api.github.com/users/rizar/events{/privacy}", "organizations_url": "https://api.github.com/users/rizar/orgs", "url": "https://api.github.com/users/rizar", "gists_url": "https://api.github.com/users/rizar/gists{/gist_id}", "html_url": "https://github.com/rizar", "subscriptions_url": "https://api.github.com/users/rizar/subscriptions", "avatar_url": "https://avatars.githubusercontent.com/u/654434?v=3", "repos_url": "https://api.github.com/users/rizar/repos", "received_events_url": "https://api.github.com/users/rizar/received_events", "gravatar_id": "", "starred_url": "https://api.github.com/users/rizar/starred{/owner}{/repo}", "site_admin": false, "login": "rizar", "type": "User", "id": 654434, "followers_url": "https://api.github.com/users/rizar/followers"}, "path": "blocks/serialization.py", "position": 331, "original_commit_id": "0db09ae47e6804b03fa496cdf3a0c83191fbcdbe", "id": 45527629}, {"original_position": 485, "diff_hunk": "@@ -180,19 +212,150 @@ def secure_dump(object_, path, dump_function=dump, **kwargs):\n     try:\n         with tempfile.NamedTemporaryFile(delete=False) as temp:\n             dump_function(object_, temp, **kwargs)\n-        shutil.move(temp.name, path)\n+        shutil.move(temp.name, file_)\n     except:\n         if \"temp\" in locals():\n             os.remove(temp.name)\n         raise\n \n \n-def continue_training(path):\n+def load(file_, name='_pkl'):\n+    \"\"\"Loads an object saved using the `dump` function.\n+\n+    By default, this function loads the object saved by the `dump`\n+    function. If some objects have been added to the archive using the\n+    `add_to_dump` function, then you can load them by passing their name\n+    to the `name` parameter.\n+\n+    Parameters\n+    ----------\n+    file_ : file\n+        The file that contains the object to load.\n+    name : str\n+        Name of the object to load. Default is `_pkl`, meaning that it is\n+        the original object which have been dumped that is loaded.\n+\n+    Returns\n+    -------\n+    The object saved in file_.\n+\n+    \"\"\"\n+    with tarfile.open(fileobj=file_, mode='r') as tar_file:\n+        p = pickle.Unpickler(\n+            tar_file.extractfile(tar_file.getmember(name)))\n+        if '_parameters' in tar_file.getnames():\n+            p.persistent_load = _PersistentLoad(tar_file)\n+        return p.load()\n+\n+\n+def load_parameters(file_):\n+    \"\"\"Loads the parameter values saved by :func:`dump`.\n+\n+    This functions loads the parameters that have been saved separately by\n+    :func:`dump`, ie the ones given to its parameter `parameters`.\n+\n+    Parameters\n+    ----------\n+    file_ : file\n+        The source to load the parameters from.\n+\n+    Returns\n+    -------\n+    A dictionary of (parameter name, numpy array) pairs.\n+\n+    \"\"\"\n+    with closing(_load_parameters_npzfile(file_)) as npz_file:\n+        return {name.replace(BRICK_DELIMITER, '/'): value\n+                for name, value in npz_file.items()}\n+\n+\n+def add_to_dump(object_, file_, name, parameters=None, use_cpickle=False,\n+                protocol=DEFAULT_PROTOCOL, **kwargs):\n+    r\"\"\"Pickles an object to an existing tar archive.\n+\n+    This function allows to dump more objects to an existing archive. If\n+    the object you want to dump posess the same set of shared variables as\n+    the object already dumped, you can pass them to the `parameters`\n+    argument, which will avoid them to be serialized a second time.\n+    However, it won't work if the shared variable you pass to the\n+    `parameters` argument are not already in the archive.\n+\n+    Parameters\n+    ----------\n+    object_ : object\n+        The object to pickle.\n+    file_ : file\n+        The destination for saving, opened in read-write mode (`r+`).\n+    name : str\n+        The name of the object you are dumping. It will be used as a file\n+        name in the archive. '_pkl' and '_paramters' are reserved names\n+        and can't be used.\n+    parameters : list, optional\n+        Shared variables whose internal numpy arrays should be saved\n+        separately in the `_parameters` field of the tar file. Must be a\n+        subset of the parameters already in the archive.\n+    use_cpickle : bool\n+        Use cPickle instead of pickle. Setting it to true will disable the\n+        warning message if you try to pickle objects from the main module!\n+        Be sure that you don't have the warning before turning this flag\n+        on. Default: False.\n+    protocol : int, optional\n+        The pickling protocol to use. Unlike Python's built-in pickle, the\n+        default is set to `2` instead of 0 for Python 2. The Python 3\n+        default (level 3) is maintained.\n+    \\*\\*kwargs\n+        Keyword arguments to be passed to `pickle.Pickler`.\n+\n+    \"\"\"\n+    if name in ['_pkl', '_parameters']:\n+        raise ValueError(\"_pkl and _parameters are reserved names and can't\" \\\n+                         \" be used as name for your object.\")\n+\n+    external_parameters = {}\n+    if parameters is not None:\n+        renamer = _Renamer()\n+        named_parameters = {renamer(p): p for p in parameters}\n+        for n, p in named_parameters.items():\n+            array_ = p.container.storage[0]\n+            external_parameters[id(array_)] = _mangle_parameter_name(\n+                type(array_), n)\n+\n+        # Check that the parameters are the same that the ones in the archive.\n+        with closing(tarfile.TarFile(fileobj=file_, mode='r')) as tar_file:\n+            if '_parameters' not in tar_file.getnames():\n+                raise ValueError(\"There is no parameters in the archive, so\" \\\n+                                 \" you can't use the argument parameters.\")\n+            else:\n+                parameters = numpy.load(\n+                    tar_file.extractfile(tar_file.getmember('_parameters')))\n+                s1 = set(parameters.keys())\n+                s2 = set(external_parameters.keys())\n+                if s1.issuperset(s2):\n+                    raise ValueError('The set of parameters is different' \\\n+                                     ' from the one in the archive.')\n+\n+    # TODO: How to avoid this hack?\n+    file_.close()\n+    file_ = open(file_.name, 'r+')\n+\n+    if use_cpickle:\n+        pickler = cPickle.Pickler\n+    else:\n+        pickler = _PicklerWithWarning\n+    with closing(tarfile.TarFile(fileobj=file_, mode='a')) as tar_file:\n+        def _save_object(f):\n+            p = pickler(f, protocol=protocol, **kwargs)\n+            p.persistent_id = _PersistentID(external_parameters)\n+            p.dump(object_)\n+        _taradd(_save_object, tar_file, name)\n+\n+\n+def continue_training(file_):\n     \"\"\"Continues training using checkpoint.\n \n     Parameters\n     ----------\n-    path : str\n+    file_ : str", "url": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/45610522", "created_at": "2015-11-23T14:49:05Z", "body": "The same question here, I think `path` is a more informative name when a string is expected.", "updated_at": "2015-11-23T14:49:05Z", "html_url": "https://github.com/mila-udem/blocks/pull/877#discussion_r45610522", "pull_request_url": "https://api.github.com/repos/mila-udem/blocks/pulls/877", "_links": {"self": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/45610522"}, "html": {"href": "https://github.com/mila-udem/blocks/pull/877#discussion_r45610522"}, "pull_request": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/877"}}, "commit_id": "0db09ae47e6804b03fa496cdf3a0c83191fbcdbe", "user": {"following_url": "https://api.github.com/users/rizar/following{/other_user}", "events_url": "https://api.github.com/users/rizar/events{/privacy}", "organizations_url": "https://api.github.com/users/rizar/orgs", "url": "https://api.github.com/users/rizar", "gists_url": "https://api.github.com/users/rizar/gists{/gist_id}", "html_url": "https://github.com/rizar", "subscriptions_url": "https://api.github.com/users/rizar/subscriptions", "avatar_url": "https://avatars.githubusercontent.com/u/654434?v=3", "repos_url": "https://api.github.com/users/rizar/repos", "received_events_url": "https://api.github.com/users/rizar/received_events", "gravatar_id": "", "starred_url": "https://api.github.com/users/rizar/starred{/owner}{/repo}", "site_admin": false, "login": "rizar", "type": "User", "id": 654434, "followers_url": "https://api.github.com/users/rizar/followers"}, "path": "blocks/serialization.py", "position": 485, "original_commit_id": "0db09ae47e6804b03fa496cdf3a0c83191fbcdbe", "id": 45610522}, {"original_position": 464, "diff_hunk": "@@ -180,19 +212,150 @@ def secure_dump(object_, path, dump_function=dump, **kwargs):\n     try:\n         with tempfile.NamedTemporaryFile(delete=False) as temp:\n             dump_function(object_, temp, **kwargs)\n-        shutil.move(temp.name, path)\n+        shutil.move(temp.name, file_)\n     except:\n         if \"temp\" in locals():\n             os.remove(temp.name)\n         raise\n \n \n-def continue_training(path):\n+def load(file_, name='_pkl'):\n+    \"\"\"Loads an object saved using the `dump` function.\n+\n+    By default, this function loads the object saved by the `dump`\n+    function. If some objects have been added to the archive using the\n+    `add_to_dump` function, then you can load them by passing their name\n+    to the `name` parameter.\n+\n+    Parameters\n+    ----------\n+    file_ : file\n+        The file that contains the object to load.\n+    name : str\n+        Name of the object to load. Default is `_pkl`, meaning that it is\n+        the original object which have been dumped that is loaded.\n+\n+    Returns\n+    -------\n+    The object saved in file_.\n+\n+    \"\"\"\n+    with tarfile.open(fileobj=file_, mode='r') as tar_file:\n+        p = pickle.Unpickler(\n+            tar_file.extractfile(tar_file.getmember(name)))\n+        if '_parameters' in tar_file.getnames():\n+            p.persistent_load = _PersistentLoad(tar_file)\n+        return p.load()\n+\n+\n+def load_parameters(file_):\n+    \"\"\"Loads the parameter values saved by :func:`dump`.\n+\n+    This functions loads the parameters that have been saved separately by\n+    :func:`dump`, ie the ones given to its parameter `parameters`.\n+\n+    Parameters\n+    ----------\n+    file_ : file\n+        The source to load the parameters from.\n+\n+    Returns\n+    -------\n+    A dictionary of (parameter name, numpy array) pairs.\n+\n+    \"\"\"\n+    with closing(_load_parameters_npzfile(file_)) as npz_file:\n+        return {name.replace(BRICK_DELIMITER, '/'): value\n+                for name, value in npz_file.items()}\n+\n+\n+def add_to_dump(object_, file_, name, parameters=None, use_cpickle=False,\n+                protocol=DEFAULT_PROTOCOL, **kwargs):\n+    r\"\"\"Pickles an object to an existing tar archive.\n+\n+    This function allows to dump more objects to an existing archive. If\n+    the object you want to dump posess the same set of shared variables as\n+    the object already dumped, you can pass them to the `parameters`\n+    argument, which will avoid them to be serialized a second time.\n+    However, it won't work if the shared variable you pass to the\n+    `parameters` argument are not already in the archive.\n+\n+    Parameters\n+    ----------\n+    object_ : object\n+        The object to pickle.\n+    file_ : file\n+        The destination for saving, opened in read-write mode (`r+`).\n+    name : str\n+        The name of the object you are dumping. It will be used as a file\n+        name in the archive. '_pkl' and '_paramters' are reserved names\n+        and can't be used.\n+    parameters : list, optional\n+        Shared variables whose internal numpy arrays should be saved\n+        separately in the `_parameters` field of the tar file. Must be a\n+        subset of the parameters already in the archive.\n+    use_cpickle : bool\n+        Use cPickle instead of pickle. Setting it to true will disable the\n+        warning message if you try to pickle objects from the main module!\n+        Be sure that you don't have the warning before turning this flag\n+        on. Default: False.\n+    protocol : int, optional\n+        The pickling protocol to use. Unlike Python's built-in pickle, the\n+        default is set to `2` instead of 0 for Python 2. The Python 3\n+        default (level 3) is maintained.\n+    \\*\\*kwargs\n+        Keyword arguments to be passed to `pickle.Pickler`.\n+\n+    \"\"\"\n+    if name in ['_pkl', '_parameters']:\n+        raise ValueError(\"_pkl and _parameters are reserved names and can't\" \\\n+                         \" be used as name for your object.\")\n+\n+    external_parameters = {}\n+    if parameters is not None:\n+        renamer = _Renamer()\n+        named_parameters = {renamer(p): p for p in parameters}\n+        for n, p in named_parameters.items():\n+            array_ = p.container.storage[0]\n+            external_parameters[id(array_)] = _mangle_parameter_name(\n+                type(array_), n)\n+\n+        # Check that the parameters are the same that the ones in the archive.\n+        with closing(tarfile.TarFile(fileobj=file_, mode='r')) as tar_file:\n+            if '_parameters' not in tar_file.getnames():\n+                raise ValueError(\"There is no parameters in the archive, so\" \\\n+                                 \" you can't use the argument parameters.\")\n+            else:\n+                parameters = numpy.load(\n+                    tar_file.extractfile(tar_file.getmember('_parameters')))\n+                s1 = set(parameters.keys())\n+                s2 = set(external_parameters.keys())\n+                if s1.issuperset(s2):\n+                    raise ValueError('The set of parameters is different' \\\n+                                     ' from the one in the archive.')\n+\n+    # TODO: How to avoid this hack?\n+    file_.close()", "url": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/45611506", "created_at": "2015-11-23T14:56:27Z", "body": "Maybe `file.seek(0)`?", "updated_at": "2015-11-23T14:56:36Z", "html_url": "https://github.com/mila-udem/blocks/pull/877#discussion_r45611506", "pull_request_url": "https://api.github.com/repos/mila-udem/blocks/pulls/877", "_links": {"self": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/comments/45611506"}, "html": {"href": "https://github.com/mila-udem/blocks/pull/877#discussion_r45611506"}, "pull_request": {"href": "https://api.github.com/repos/mila-udem/blocks/pulls/877"}}, "commit_id": "0db09ae47e6804b03fa496cdf3a0c83191fbcdbe", "user": {"following_url": "https://api.github.com/users/rizar/following{/other_user}", "events_url": "https://api.github.com/users/rizar/events{/privacy}", "organizations_url": "https://api.github.com/users/rizar/orgs", "url": "https://api.github.com/users/rizar", "gists_url": "https://api.github.com/users/rizar/gists{/gist_id}", "html_url": "https://github.com/rizar", "subscriptions_url": "https://api.github.com/users/rizar/subscriptions", "avatar_url": "https://avatars.githubusercontent.com/u/654434?v=3", "repos_url": "https://api.github.com/users/rizar/repos", "received_events_url": "https://api.github.com/users/rizar/received_events", "gravatar_id": "", "starred_url": "https://api.github.com/users/rizar/starred{/owner}{/repo}", "site_admin": false, "login": "rizar", "type": "User", "id": 654434, "followers_url": "https://api.github.com/users/rizar/followers"}, "path": "blocks/serialization.py", "position": 464, "original_commit_id": "0db09ae47e6804b03fa496cdf3a0c83191fbcdbe", "id": 45611506}]